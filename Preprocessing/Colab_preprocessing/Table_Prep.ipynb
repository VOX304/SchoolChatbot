{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML+HgapDQ7kA5St6E8WbXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VOX304/SchoolChatbot/blob/main/Preprocessing/Colab_preprocessing/Table_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr1GeD3jqFL-",
        "outputId": "0f90f10d-be21-4333-a2ae-7cabdc41ebe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: vietocr in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: boundbox in /usr/local/lib/python3.11/dist-packages (0.0.5)\n",
            "Requirement already satisfied: markdown-table in /usr/local/lib/python3.11/dist-packages (2020.12.3)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (10.2.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: einops==0.2.0 in /usr/local/lib/python3.11/dist-packages (from vietocr) (0.2.0)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.11/dist-packages (from vietocr) (4.4.0)\n",
            "Requirement already satisfied: prefetch-generator==1.0.1 in /usr/local/lib/python3.11/dist-packages (from vietocr) (1.0.1)\n",
            "Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.11/dist-packages (from vietocr) (0.4.0)\n",
            "Requirement already satisfied: albumentations==1.4.2 in /usr/local/lib/python3.11/dist-packages (from vietocr) (1.4.2)\n",
            "Requirement already satisfied: lmdb>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from vietocr) (1.6.2)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from vietocr) (0.25.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.2->vietocr) (1.14.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.2->vietocr) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.2->vietocr) (1.6.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.2->vietocr) (4.11.0.86)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown==4.4.0->vietocr) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown==4.4.0->vietocr) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from gdown==4.4.0->vietocr) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown==4.4.0->vietocr) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown==4.4.0->vietocr) (4.13.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug==0.4.0->vietocr) (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug==0.4.0->vietocr) (2.37.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug==0.4.0->vietocr) (2.0.7)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->vietocr) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->vietocr) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->vietocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->vietocr) (0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.2->vietocr) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.2->vietocr) (3.6.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown==4.4.0->vietocr) (2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug==0.4.0->vietocr) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug==0.4.0->vietocr) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug==0.4.0->vietocr) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug==0.4.0->vietocr) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug==0.4.0->vietocr) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug==0.4.0->vietocr) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.4.0->vietocr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.4.0->vietocr) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.4.0->vietocr) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown==4.4.0->vietocr) (1.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber python-docx opencv-python numpy vietocr boundbox markdown-table\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markdown-table\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCPmQCBKs1f_",
        "outputId": "30991bde-936c-41a7-e8b5-4a05497ee50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: markdown-table in /usr/local/lib/python3.11/dist-packages (2020.12.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y libreoffice\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x_H9H0xyosE",
        "outputId": "3963c312-9c25-447c-e433-7952f5aee40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "30 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install pdf2image\n",
        "!apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuJi0CkwcxJG",
        "outputId": "e429794f-2264-4087-a31c-e6b2acf23bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (10.2.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (10.2.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,668 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 134513 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def is_text_valid(text, threshold=0.5):\n",
        "    \"\"\"Check if extracted text is valid or gibberish based on character ratios.\"\"\"\n",
        "    non_alpha_chars = sum(1 for char in text if not char.isalnum() and char not in \" \\n\")\n",
        "    alpha_chars = sum(1 for char in text if char.isalnum())\n",
        "\n",
        "    if alpha_chars == 0:\n",
        "        return False  # All non-alphanumeric, probably junk\n",
        "\n",
        "    non_alpha_ratio = non_alpha_chars / (alpha_chars + non_alpha_chars)\n",
        "    return non_alpha_ratio < threshold  # If too many non-alphanumeric chars, it's bad\n",
        "\n",
        "def extract_table_text_based(file_path):\n",
        "    \"\"\"Extract table data from PDFs or DOCX files, fallback to OCR if text is bad.\"\"\"\n",
        "    tables = []\n",
        "\n",
        "    if file_path.endswith('.pdf'):\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                extracted_text = page.extract_text()\n",
        "\n",
        "                if not extracted_text or not is_text_valid(extracted_text):\n",
        "                    print(\"⚠️ Poor text quality detected. Switching to OCR-based extraction.\")\n",
        "                    tables.extend(extract_table_from_image_pdf(file_path))\n",
        "                    return tables  # Return early since we used image OCR\n",
        "\n",
        "                tables.extend(page.extract_tables())\n",
        "\n",
        "    elif file_path.endswith('.docx'):\n",
        "        doc = docx.Document(file_path)\n",
        "        for table in doc.tables:\n",
        "            rows = [[cell.text for cell in row.cells] for row in table.rows]\n",
        "            tables.append(rows)\n",
        "\n",
        "    return tables\n",
        "\n",
        "def extract_table_from_image_pdf(file_path):\n",
        "    \"\"\"Convert PDF pages to images and extract tables using OCR.\"\"\"\n",
        "    tables = []\n",
        "    images = convert_from_path(file_path, dpi=300)  # Convert PDF to images\n",
        "\n",
        "    for img in images:\n",
        "        text = pytesseract.image_to_string(img)\n",
        "        structured_table = reconstruct_table_structure(text, img)\n",
        "        tables.append(structured_table)\n",
        "\n",
        "    return tables\n"
      ],
      "metadata": {
        "id": "z35SPO7-cmJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def align_text_to_grid(text, contours):\n",
        "    \"\"\"Align OCR-extracted text to a table grid using contour detection.\"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # Sort contours top-to-bottom (to process rows correctly)\n",
        "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[1])\n",
        "\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Extract text inside this cell\n",
        "        cell_text = text.strip()\n",
        "        rows.append(cell_text)\n",
        "\n",
        "    return [rows]  # Return as a list of lists (table format)\n"
      ],
      "metadata": {
        "id": "GJbOUHy6cDCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_table_structure(text, image):\n",
        "    \"\"\"Use contour detection & grid alignment to reconstruct table format.\"\"\"\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    structured_data = align_text_to_grid(text, contours)\n",
        "    return structured_data\n"
      ],
      "metadata": {
        "id": "2r9yCSFPcIFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "def convert_doc_to_docx(doc_path):\n",
        "    \"\"\"Convert a .doc file to .docx using LibreOffice.\"\"\"\n",
        "    output_path = doc_path.rsplit(\".\", 1)[0] + \".docx\"\n",
        "\n",
        "    if not os.path.exists(doc_path):\n",
        "        raise FileNotFoundError(f\"File not found: {doc_path}\")\n",
        "\n",
        "    os.system(f'soffice --headless --convert-to docx \"{doc_path}\"')\n",
        "\n",
        "    # Wait for the file to appear (up to 5 seconds)\n",
        "    timeout = 7\n",
        "    while timeout > 0:\n",
        "        if os.path.exists(output_path):\n",
        "            return output_path\n",
        "        time.sleep(1)\n",
        "        timeout -= 1\n",
        "\n",
        "    raise FileNotFoundError(f\"Conversion failed. No .docx file found at {output_path}\")\n"
      ],
      "metadata": {
        "id": "khwATmfeyDzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_in_markdown_file(markdown_tables, output_file=\"tables.md\"):\n",
        "    \"\"\"Save extracted tables in a Markdown file.\"\"\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for table in markdown_tables:\n",
        "            f.write(table + \"\\n\\n\")  # Separate tables with a newline\n",
        "    print(f\"Tables saved to {output_file}\")\n"
      ],
      "metadata": {
        "id": "a9FyH5J-5TqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import docx\n",
        "import cv2\n",
        "import numpy as np\n",
        "from vietocr.tool.predictor import Predictor\n",
        "from vietocr.tool.config import Cfg\n",
        "\n",
        "# Load OCR model\n",
        "config = Cfg.load_config_from_name('vgg_transformer')\n",
        "config['device'] = 'cpu'  # Change to 'cuda' if GPU available\n",
        "ocr_model = Predictor(config)\n",
        "\n",
        "def detect_table_presence(file_path):\n",
        "    \"\"\"Determine if a document contains tables and whether they are text-based or image-based.\"\"\"\n",
        "    if file_path.endswith('.pdf'):\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                if page.extract_tables():\n",
        "                    return 'text'\n",
        "        return 'image'\n",
        "    elif file_path.endswith('.docx'):\n",
        "        doc = docx.Document(file_path)\n",
        "        for table in doc.tables:\n",
        "            return 'text'\n",
        "    return 'image'\n",
        "\n",
        "def detect_table(image_path):\n",
        "    \"\"\"Detect tables using OpenCV.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Error: Could not load image from {image_path}. Check file path and format.\")\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Table bounding boxes\n",
        "    tables = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "    return tables\n",
        "\n",
        "def extract_table_text_based(file_path):\n",
        "    \"\"\"Extract table data from text-based PDFs or DOCX files.\"\"\"\n",
        "    tables = []\n",
        "    if file_path.endswith('.pdf'):\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                tables.extend(page.extract_tables())\n",
        "    elif file_path.endswith('.docx'):\n",
        "        doc = docx.Document(file_path)\n",
        "        for table in doc.tables:\n",
        "            rows = [[cell.text for cell in row.cells] for row in table.rows]\n",
        "            tables.append(rows)\n",
        "    return tables\n",
        "\n",
        "def apply_ocr_to_image(image):\n",
        "    \"\"\"Use VietOCR to recognize text from an image.\"\"\"\n",
        "    return ocr_model.predict(image)\n",
        "\n",
        "def extract_table_from_image(image_path):\n",
        "    \"\"\"Apply BoundBox + OCR to extract tables from image-based PDFs.\"\"\"\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    tables = detect_table(image)  # Detect table boundaries\n",
        "    extracted_tables = []\n",
        "\n",
        "    for table in tables:\n",
        "        x, y, w, h = table  # Table bounding box\n",
        "        cropped_table = image[y:y+h, x:x+w]\n",
        "        text = apply_ocr_to_image(cropped_table)\n",
        "        structured_table = reconstruct_table_structure(text, cropped_table)\n",
        "        extracted_tables.append(structured_table)\n",
        "\n",
        "    return extracted_tables\n",
        "\n",
        "def reconstruct_table_structure(text, image):\n",
        "    \"\"\"Use contour detection & grid alignment to reconstruct table format.\"\"\"\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    structured_data = align_text_to_grid(text, contours)\n",
        "    return structured_data\n",
        "\n",
        "def convert_tables_to_markdown(tables):\n",
        "    \"\"\"Convert extracted tables into Markdown format.\"\"\"\n",
        "    return [convert_to_markdown(table) for table in tables]\n",
        "\n",
        "def convert_to_markdown(table_data):\n",
        "    \"\"\"Convert extracted table data (list of lists) into Markdown format.\"\"\"\n",
        "    if not table_data:\n",
        "        return \"\"\n",
        "\n",
        "    markdown = \"| \" + \" | \".join(table_data[0]) + \" |\\n\"\n",
        "    markdown += \"| \" + \" | \".join([\"---\"] * len(table_data[0])) + \" |\\n\"\n",
        "\n",
        "    for row in table_data[1:]:\n",
        "        markdown += \"| \" + \" | \".join(row) + \" |\\n\"\n",
        "\n",
        "    return markdown\n",
        "\n",
        "\n",
        "def store_in_vectordb(markdown_tables):\n",
        "    \"\"\"Store processed Markdown tables into a VectorDB for retrieval.\"\"\"\n",
        "    for table in markdown_tables:\n",
        "        print(\"Storing table in VectorDB:\\n\", table)\n",
        "    # VectorDB storage logic here (FAISS, Pinecone, etc.)\n",
        "\n",
        "def process_document(file_path):\n",
        "    \"\"\"Complete pipeline: Detect table type, extract, convert to Markdown, and store in VectorDB.\"\"\"\n",
        "    table_type = detect_table_presence(file_path)\n",
        "\n",
        "    if table_type == 'text':\n",
        "        tables = extract_table_text_based(file_path)\n",
        "    else:\n",
        "        tables = extract_table_from_image(file_path)\n",
        "\n",
        "    markdown_tables = convert_tables_to_markdown(tables)\n",
        "\n",
        "    store_in_markdown_file(markdown_tables, output_file=\"extracted_tables.md\")\n",
        "    print(\"Table processing completed.\")\n",
        "\n",
        "# Example usage:\n",
        "# process_document(\"example.pdf\")\n"
      ],
      "metadata": {
        "id": "PoXKluSkqVPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txGDIkwn5Rw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/HD1860 công tác xét tuyển đào tạo ĐH, CĐ năm 2024_20252211126.pdf\"\n",
        "\n",
        "res = pdfplumber.open(file_path)\n",
        "print_result = res.pages[0].extract_text()\n",
        "print(print_result)\n",
        "#converted_path = convert_doc_to_docx(file_path)\n",
        "\n",
        "#print(\"Converted file path:\", converted_path)"
      ],
      "metadata": {
        "id": "yd_INGmBzKCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}