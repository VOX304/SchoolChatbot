{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3dd7178-8337-44f0-a468-bc1af5c0e811",
      "metadata": {
        "id": "d3dd7178-8337-44f0-a468-bc1af5c0e811"
      },
      "source": [
        "# How to load PDFs\n",
        "\n",
        "[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\n",
        "\n",
        "This guide covers how to [load](/docs/concepts/document_loaders/) `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that we use downstream.\n",
        "\n",
        "Text in PDFs is typically represented via text boxes. They may also contain images. A PDF parser might do some combination of the following:\n",
        "\n",
        "- Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference;\n",
        "- Run [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) on images to detect text therein;\n",
        "- Classify text as belonging to paragraphs, lists, tables, or other structures;\n",
        "- Structure text into table rows and columns, or key-value pairs.\n",
        "\n",
        "LangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your needs. Below we enumerate the possibilities.\n",
        "\n",
        "We will demonstrate these approaches on a [sample file](https://github.com/langchain-ai/langchain/blob/master/libs/community/tests/integration_tests/examples/layout-parser-paper.pdf):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b5c65c1-1f12-4dc1-98f0-9a5b2bf8ebc2",
      "metadata": {
        "id": "3b5c65c1-1f12-4dc1-98f0-9a5b2bf8ebc2"
      },
      "outputs": [],
      "source": [
        "file_path = (\n",
        "    \"/CSE Module Handbook.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5a5bc0d-4e92-4c0d-94c8-5699c5a2a2db",
      "metadata": {
        "id": "d5a5bc0d-4e92-4c0d-94c8-5699c5a2a2db"
      },
      "source": [
        ":::info A note on multimodal models\n",
        "\n",
        "Many modern LLMs support inference over multimodal inputs (e.g., images). In some applications -- such as question-answering over PDFs with complex layouts, diagrams, or scans -- it may be advantageous to skip the PDF parsing, instead casting a PDF page to an image and passing it to a model directly. We demonstrate an example of this in the [Use of multimodal models](/docs/how_to/document_loader_pdf/#use-of-multimodal-models) section below.\n",
        "\n",
        ":::\n",
        "\n",
        "## Simple and fast text extraction\n",
        "\n",
        "If you are looking for a simple string representation of text that is embedded in a PDF, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects-- one per page-- containing a single string of the page's text in the Document's `page_content` attribute. It will not parse text in images or scanned PDF pages. Under the hood it uses the [pypdf](https://pypdf.readthedocs.io/en/stable/) Python library.\n",
        "\n",
        "LangChain [document loaders](/docs/concepts/document_loaders) implement `lazy_load` and its async variant, `alazy_load`, which return iterators of `Document` objects. We will use these below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PznxWJkxJYuS",
        "outputId": "2855251b-8642-44dc-9104-705df80716be"
      },
      "id": "PznxWJkxJYuS",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain_community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.43)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.13)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35c08d82-8b0a-45e2-8167-73e70f88208a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35c08d82-8b0a-45e2-8167-73e70f88208a",
        "outputId": "6613e9fc-e31b-4b7a-ee86-d0a2b0ded248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0746557c-6f65-43a4-a15e-8d270e6c1349",
      "metadata": {
        "id": "0746557c-6f65-43a4-a15e-8d270e6c1349",
        "outputId": "75a79b74-597d-40c2-bda5-6d3e80219989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File path /CSE Module Handbook.pdf is not a valid file or url",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-299f5456d9b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0maload\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mto\u001b[0m \u001b[0mretrieve\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         self.parser = PyPDFParser(\n\u001b[1;32m    283\u001b[0m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File path %s is not a valid file or url\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File path /CSE Module Handbook.pdf is not a valid file or url"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = []\n",
        "async for page in loader.alazy_load():\n",
        "    pages.append(page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "839bde4a-e490-413e-93a4-cce4468f2f34",
      "metadata": {
        "id": "839bde4a-e490-413e-93a4-cce4468f2f34"
      },
      "outputs": [],
      "source": [
        "print(f\"{pages[0].metadata}\\n\")\n",
        "print(pages[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ce6d1d-86cc-45e3-8259-e21fbd2c7e6c",
      "metadata": {
        "id": "78ce6d1d-86cc-45e3-8259-e21fbd2c7e6c"
      },
      "source": [
        "Note that the metadata of each document stores the corresponding page number.\n",
        "\n",
        "### Vector search over PDFs\n",
        "\n",
        "Once we have loaded PDFs into LangChain `Document` objects, we can index them (e.g., a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain [embeddings](https://python.langchain.com/docs/concepts/embedding_models) model will suffice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba35f1c-0a85-4f2f-a56e-3a994c69180d",
      "metadata": {
        "id": "7ba35f1c-0a85-4f2f-a56e-3a994c69180d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-thinking-exp-01-21\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0eaec77-f5cf-4172-8e39-41e1520eabba",
      "metadata": {
        "id": "e0eaec77-f5cf-4172-8e39-41e1520eabba"
      },
      "outputs": [],
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "vector_store = InMemoryVectorStore.from_documents(pages, embeddings)\n",
        "docs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\n",
        "for doc in docs:\n",
        "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef200c75-a141-45d9-acdc-261e4d632d1b",
      "metadata": {
        "id": "ef200c75-a141-45d9-acdc-261e4d632d1b"
      },
      "source": [
        "## Layout analysis and extraction of text from images\n",
        "\n",
        "If you require a more granular segmentation of text (e.g., into distinct paragraphs, titles, tables, or other structures) or require extraction of text from images, the method below is appropriate. It will return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, where each object represents a structure on the page. The Document's metadata stores the page number and other information related to the object (e.g., it might store table rows and columns in the case of a table object).\n",
        "\n",
        "Under the hood it uses the `langchain-unstructured` library. See the [integration docs](/docs/integrations/document_loaders/unstructured_file/) for more information about using [Unstructured](https://docs.unstructured.io/welcome) with LangChain.\n",
        "\n",
        "Unstructured supports multiple parameters for PDF parsing:\n",
        "- `strategy` (e.g., `\"fast\"` or `\"hi-res\"`)\n",
        "- API or local processing. You will need an API key to use the API.\n",
        "\n",
        "The [hi-res](https://docs.unstructured.io/api-reference/how-to/choose-hi-res-model) strategy provides support for document layout analysis and OCR. We demonstrate it below via the API. See [local parsing](/docs/how_to/document_loader_pdf/#local-parsing) section below for considerations when running locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b448489a-c1a5-43c8-a69f-1c1e7bc26b69",
      "metadata": {
        "id": "b448489a-c1a5-43c8-a69f-1c1e7bc26b69"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc403c36-25a0-4fc0-b31a-cc2022f8e5a9",
      "metadata": {
        "id": "dc403c36-25a0-4fc0-b31a-cc2022f8e5a9"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"UNSTRUCTURED_API_KEY\"] = userdata.get('UNSTRUCTURED_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a024db-bec2-4f21-b4a8-dd6b94fd0d21",
      "metadata": {
        "id": "12a024db-bec2-4f21-b4a8-dd6b94fd0d21"
      },
      "source": [
        "As before, we initialize a loader and load documents lazily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0575c3-566b-4e26-99c8-ae69b53cfb09",
      "metadata": {
        "id": "be0575c3-566b-4e26-99c8-ae69b53cfb09"
      },
      "outputs": [],
      "source": [
        "from langchain_unstructured import UnstructuredLoader\n",
        "\n",
        "loader = UnstructuredLoader(\n",
        "    file_path=file_path,\n",
        "    strategy=\"hi_res\",\n",
        "    partition_via_api=True,\n",
        "    coordinates=True,\n",
        ")\n",
        "docs = []\n",
        "for doc in loader.lazy_load():\n",
        "    docs.append(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f20eff-3df7-425d-84ab-70a76e5f22ce",
      "metadata": {
        "id": "a9f20eff-3df7-425d-84ab-70a76e5f22ce"
      },
      "source": [
        "Here we recover 171 distinct structures over the 16 page document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35945b71-f2ca-4480-be18-c8fcc0a7035f",
      "metadata": {
        "id": "35945b71-f2ca-4480-be18-c8fcc0a7035f"
      },
      "outputs": [],
      "source": [
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619eb7c5-69d9-4d8b-9aa1-fbdd015bb8cd",
      "metadata": {
        "id": "619eb7c5-69d9-4d8b-9aa1-fbdd015bb8cd"
      },
      "source": [
        "We can use the document metadata to recover content from a single page:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648876b4-a686-489d-8a82-d7df4e78754c",
      "metadata": {
        "id": "648876b4-a686-489d-8a82-d7df4e78754c"
      },
      "outputs": [],
      "source": [
        "first_page_docs = [doc for doc in docs if doc.metadata.get(\"page_number\") == 1]\n",
        "\n",
        "for doc in first_page_docs:\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41c07f49-091d-4197-afea-c36f30196f31",
      "metadata": {
        "id": "41c07f49-091d-4197-afea-c36f30196f31"
      },
      "source": [
        "### Extracting tables and other structures\n",
        "\n",
        "Each `Document` we load represents a structure, like a title, paragraph, or table.\n",
        "\n",
        "Some structures may be of special interest for indexing or question-answering tasks. These structures may be:\n",
        "1. Classified for easy identification;\n",
        "2. Parsed into a more structured representation.\n",
        "\n",
        "Below, we identify and extract a table:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cccf340-e272-41af-8280-6e97ca687d45",
      "metadata": {
        "id": "4cccf340-e272-41af-8280-6e97ca687d45"
      },
      "source": [
        "<details>\n",
        "<summary>Click to expand code for rendering pages</summary>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU matplotlib PyMuPDF pillow"
      ],
      "metadata": {
        "id": "QLHdWJnIQ68w"
      },
      "id": "QLHdWJnIQ68w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cedb6a7-bd75-4270-9d49-b6806f7cd7c4",
      "metadata": {
        "id": "5cedb6a7-bd75-4270-9d49-b6806f7cd7c4"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def plot_pdf_with_boxes(pdf_page, segments):\n",
        "    pix = pdf_page.get_pixmap()\n",
        "    pil_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "\n",
        "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
        "    ax.imshow(pil_image)\n",
        "    categories = set()\n",
        "    category_to_color = {\n",
        "        \"Title\": \"orchid\",\n",
        "        \"Image\": \"forestgreen\",\n",
        "        \"Table\": \"tomato\",\n",
        "    }\n",
        "    for segment in segments:\n",
        "        points = segment[\"coordinates\"][\"points\"]\n",
        "        layout_width = segment[\"coordinates\"][\"layout_width\"]\n",
        "        layout_height = segment[\"coordinates\"][\"layout_height\"]\n",
        "        scaled_points = [\n",
        "            (x * pix.width / layout_width, y * pix.height / layout_height)\n",
        "            for x, y in points\n",
        "        ]\n",
        "        box_color = category_to_color.get(segment[\"category\"], \"deepskyblue\")\n",
        "        categories.add(segment[\"category\"])\n",
        "        rect = patches.Polygon(\n",
        "            scaled_points, linewidth=1, edgecolor=box_color, facecolor=\"none\"\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Make legend\n",
        "    legend_handles = [patches.Patch(color=\"deepskyblue\", label=\"Text\")]\n",
        "    for category in [\"Title\", \"Image\", \"Table\"]:\n",
        "        if category in categories:\n",
        "            legend_handles.append(\n",
        "                patches.Patch(color=category_to_color[category], label=category)\n",
        "            )\n",
        "    ax.axis(\"off\")\n",
        "    ax.legend(handles=legend_handles, loc=\"upper right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def render_page(doc_list: list, page_number: int, print_text=True) -> None:\n",
        "    pdf_page = fitz.open(file_path).load_page(page_number - 1)\n",
        "    page_docs = [\n",
        "        doc for doc in doc_list if doc.metadata.get(\"page_number\") == page_number\n",
        "    ]\n",
        "    segments = [doc.metadata for doc in page_docs]\n",
        "    plot_pdf_with_boxes(pdf_page, segments)\n",
        "    if print_text:\n",
        "        for doc in page_docs:\n",
        "            print(f\"{doc.page_content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a9e09d-fed1-42aa-9a8e-07aeedbc5388",
      "metadata": {
        "id": "91a9e09d-fed1-42aa-9a8e-07aeedbc5388"
      },
      "source": [
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b44ab2e-52df-4af6-9950-b3f5b46a9b47",
      "metadata": {
        "id": "6b44ab2e-52df-4af6-9950-b3f5b46a9b47"
      },
      "outputs": [],
      "source": [
        "render_page(docs, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0267a271-e1bd-483c-96c3-36eb1387dd3f",
      "metadata": {
        "id": "0267a271-e1bd-483c-96c3-36eb1387dd3f"
      },
      "source": [
        "Note that although the table text is collapsed into a single string in the document's content, the metadata contains a representation of its rows and columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f91df64-94db-4228-8a75-34bf83117e15",
      "metadata": {
        "id": "3f91df64-94db-4228-8a75-34bf83117e15"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "segments = [\n",
        "    doc.metadata\n",
        "    for doc in docs\n",
        "    if doc.metadata.get(\"page_number\") == 5 and doc.metadata.get(\"category\") == \"Table\"\n",
        "]\n",
        "\n",
        "display(HTML(segments[0][\"text_as_html\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac2c37a-06a1-40d3-a192-9078eb83994b",
      "metadata": {
        "id": "3ac2c37a-06a1-40d3-a192-9078eb83994b"
      },
      "source": [
        "<table><thead><tr><th colspan=\"3\">able 1. LUllclll 1ayoul actCCLloll 1110AdCs 111 L1C LayoOulralsel 1110U4cl 200</th></tr><tr><th>Dataset</th><th>| Base Model\\'|</th><th>Notes</th></tr></thead><tbody><tr><td>PubLayNet [38]</td><td>F/M</td><td>Layouts of modern scientific documents</td></tr><tr><td>PRImA</td><td>M</td><td>Layouts of scanned modern magazines and scientific reports</td></tr><tr><td>Newspaper</td><td>F</td><td>Layouts of scanned US newspapers from the 20th century</td></tr><tr><td>TableBank [18]</td><td>F</td><td>Table region on modern scientific and business document</td></tr><tr><td>HJDataset</td><td>F/M</td><td>Layouts of history Japanese documents</td></tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c16d24f8-be5f-4616-9a79-9761788b30f8",
      "metadata": {
        "id": "c16d24f8-be5f-4616-9a79-9761788b30f8"
      },
      "source": [
        "### Extracting text from specific sections\n",
        "\n",
        "Structures may have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding `Document` objects.\n",
        "\n",
        "Below, we extract all text associated with the document's \"Conclusion\" section:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb9f9e1-3a64-40bc-bea8-7ab74e3a4ca2",
      "metadata": {
        "id": "abb9f9e1-3a64-40bc-bea8-7ab74e3a4ca2"
      },
      "outputs": [],
      "source": [
        "render_page(docs, 14, print_text=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9155a30-ad45-4eec-b707-8142a9c27e0e",
      "metadata": {
        "id": "a9155a30-ad45-4eec-b707-8142a9c27e0e"
      },
      "outputs": [],
      "source": [
        "conclusion_docs = []\n",
        "parent_id = -1\n",
        "for doc in docs:\n",
        "    if doc.metadata[\"category\"] == \"Title\" and \"Conclusion\" in doc.page_content:\n",
        "        parent_id = doc.metadata[\"element_id\"]\n",
        "    if doc.metadata.get(\"parent_id\") == parent_id:\n",
        "        conclusion_docs.append(doc)\n",
        "\n",
        "for doc in conclusion_docs:\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d3be20-7adc-4a96-a97e-4777eb79b0cc",
      "metadata": {
        "id": "23d3be20-7adc-4a96-a97e-4777eb79b0cc"
      },
      "source": [
        "### Extracting text from images\n",
        "\n",
        "OCR is run on images, enabling the extraction of text therein:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a17993b-13d0-42f4-a3ec-4e4a600cc65c",
      "metadata": {
        "id": "3a17993b-13d0-42f4-a3ec-4e4a600cc65c"
      },
      "outputs": [],
      "source": [
        "render_page(docs, 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a1082e2-ba2f-407f-8334-7636a126286d",
      "metadata": {
        "id": "8a1082e2-ba2f-407f-8334-7636a126286d"
      },
      "source": [
        "Note that the text from the figure on the right is extracted and incorporated into the content of the `Document`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54be5d8-8492-4ea1-b67d-e6d2d6479313",
      "metadata": {
        "id": "e54be5d8-8492-4ea1-b67d-e6d2d6479313"
      },
      "source": [
        "### Local parsing\n",
        "\n",
        "Parsing locally requires the installation of additional dependencies.\n",
        "\n",
        "**Poppler** (PDF analysis)\n",
        "- Linux: `apt-get install poppler-utils`\n",
        "- Mac: `brew install poppler`\n",
        "- Windows: https://github.com/oschwartz10612/poppler-windows\n",
        "\n",
        "**Tesseract** (OCR)\n",
        "- Linux: `apt-get install tesseract-ocr`\n",
        "- Mac: `brew install tesseract`\n",
        "- Windows: https://github.com/UB-Mannheim/tesseract/wiki#tesseract-installer-for-windows\n",
        "\n",
        "We will also need to install the `unstructured` PDF extras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23babb2-d538-437e-b26a-5e5e002c42a8",
      "metadata": {
        "id": "d23babb2-d538-437e-b26a-5e5e002c42a8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}